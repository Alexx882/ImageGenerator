{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "load = False  # should stored weights be loaded from the disk?\n",
    "train = True  # should the model be trained? \n",
    "export = True # should the weights be exported? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_MNIST(keras.Model):\n",
    "    '''\n",
    "    This class represents the autoencoder (not variational!) as it is proposed in\n",
    "    \"Generative Adversarial Networks with Decoder-Encoder Output Noise\", Table 2.\n",
    "    \n",
    "    The paper was written by: Guoqiang Zhong, Member, IEEE, Wei Gao, Yongbin Liu, \n",
    "    Youzhao Yang\n",
    "    '''\n",
    "    def __init__(self, latent_dim, path=\"vae_save\", load=False, **kwargs):\n",
    "        super(AE_MNIST, self).__init__(**kwargs)\n",
    "        \n",
    "        self.path = path\n",
    "        self.load = load\n",
    "        \n",
    "        self.encoder = self.build_encoder(latent_dim)\n",
    "        self.decoder = self.build_decoder(latent_dim)\n",
    "    \n",
    "    def export(self):\n",
    "        self.encoder.save(f\"{self.path}/encoder_weights.h5\")\n",
    "        self.decoder.save(f\"{self.path}/decoder_weights.h5\")\n",
    "    \n",
    "    def build_decoder(self, latent_dim):\n",
    "        '''\n",
    "        Build the encoder network. \n",
    "        '''\n",
    "        latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "        x = layers.Dense(128, activation=\"relu\")(latent_inputs)\n",
    "        x = layers.Dense(784, activation=\"relu\")(x)\n",
    "        x = layers.Reshape((28,28,1))(x)\n",
    "        \n",
    "        x = layers.Conv2DTranspose(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        x = layers.Conv2DTranspose(1, 5, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(784)(x)\n",
    "        x = layers.Reshape((28,28,1))(x)\n",
    "        \n",
    "        decoder = keras.Model(latent_inputs, x, name=\"decoder\")\n",
    "        # decoder.summary()\n",
    "\n",
    "        if self.load:\n",
    "            decoder.load_weights(f\"{self.path}/decoder_weights.h5\")\n",
    "        \n",
    "        return decoder\n",
    "    \n",
    "    def build_encoder(self, latent_dim):\n",
    "        encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "        x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "        x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        x = layers.Conv2D(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        \n",
    "        encoder = keras.Model(encoder_inputs, x, name=\"encoder\")\n",
    "        # encoder.summary()\n",
    "\n",
    "        if self.load:\n",
    "            encoder.load_weights(f\"{self.path}vae_save/encoder_weights.h5\")\n",
    "        \n",
    "        return encoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            encoded = self.encoder(data)\n",
    "            reconstruction = self.decoder(encoded)\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= 28 * 28\n",
    "            total_loss = reconstruction_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MNIST data and merge training and test data\n",
    "(x_train, y_train), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the autoencoder and give it a path where to store images and its model\n",
    "vae = AE_MNIST(128, path=\"ae_degan_mnist\", load=load)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B4320D1EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B4320D1AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b4320ca9d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = mnist_digits[0].reshape(-1, 28, 28, 1)\n",
    "\n",
    "plt.imshow(image.reshape(28,28))\n",
    "\n",
    "encoded = vae.encoder.predict(image)\n",
    "decoded = vae.decoder.predict(encoded)\n",
    "\n",
    "plt.imshow(decoded.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/547 [=====>........................] - ETA: 24:34 - loss: 2604.7349 - reconstruction_loss: 2604.7349"
     ]
    }
   ],
   "source": [
    "# training\n",
    "if train:\n",
    "    vae.export()\n",
    "    \n",
    "    while True:\n",
    "        vae.fit(mnist_digits, epochs=1, batch_size=128)\n",
    "        vae.export()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
