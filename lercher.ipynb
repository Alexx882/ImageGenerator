{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Resolution Deep Convolutional Generative Adversarial Networks\n",
    "J. D. Curt√≥, I. C. Zarza, Fernando de la Torre, Irwin King, Michael R. Lyu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crawler import crawler, purify_sources\n",
    "\n",
    "# load urls of images into local file\n",
    "crawler.run()\n",
    "purify_sources.purify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crawler import downloader\n",
    "\n",
    "# download actual images into folder\n",
    "downloader.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import cropper\n",
    "\n",
    "cropper.crop_to_face()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(60000, 28, 28, 1)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1) / 255.\n",
    "# x_train = x_train[:500,]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gan import GAN, DCGAN\n",
    "\n",
    "gan = DCGAN(shape=(28,28,1), train_combined=False)\n",
    "\n",
    "gan.set_training_data(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gan.generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " Generator loss: 0.5150130987167358\nIteration 277: Discriminator loss: 1.4074026346206665, Generator loss: 0.5154104232788086\nIteration 278: Discriminator loss: 1.406649112701416, Generator loss: 0.5155972242355347\nIteration 279: Discriminator loss: 1.4077990055084229, Generator loss: 0.5158543586730957\nIteration 280: Discriminator loss: 1.404463768005371, Generator loss: 0.5168083906173706\nIteration 281: Discriminator loss: 1.4061520099639893, Generator loss: 0.5166067481040955\nIteration 282: Discriminator loss: 1.4061834812164307, Generator loss: 0.5177605152130127\nIteration 283: Discriminator loss: 1.407599925994873, Generator loss: 0.5173537731170654\nIteration 284: Discriminator loss: 1.4057005643844604, Generator loss: 0.5183120965957642\nIteration 285: Discriminator loss: 1.404872179031372, Generator loss: 0.5180820226669312\nIteration 286: Discriminator loss: 1.4045696258544922, Generator loss: 0.5188148617744446\nIteration 287: Discriminator loss: 1.4036763906478882, Generator loss: 0.5190423727035522\nIteration 288: Discriminator loss: 1.4018584489822388, Generator loss: 0.5195372104644775\nIteration 289: Discriminator loss: 1.4032350778579712, Generator loss: 0.5196423530578613\nIteration 290: Discriminator loss: 1.402595043182373, Generator loss: 0.520118772983551\nIteration 291: Discriminator loss: 1.402585506439209, Generator loss: 0.5204794406890869\nIteration 292: Discriminator loss: 1.4028469324111938, Generator loss: 0.5206649303436279\nIteration 293: Discriminator loss: 1.4026638269424438, Generator loss: 0.521724283695221\nIteration 294: Discriminator loss: 1.4025071859359741, Generator loss: 0.5218610167503357\nIteration 295: Discriminator loss: 1.401728868484497, Generator loss: 0.52214115858078\nIteration 296: Discriminator loss: 1.4009449481964111, Generator loss: 0.5227279663085938\nIteration 297: Discriminator loss: 1.3995157480239868, Generator loss: 0.523034393787384\nIteration 298: Discriminator loss: 1.4026494026184082, Generator loss: 0.5232142806053162\nIteration 299: Discriminator loss: 1.3999638557434082, Generator loss: 0.5233220458030701\nIteration 300: Discriminator loss: 1.4015631675720215, Generator loss: 0.5237832069396973\nIteration 301: Discriminator loss: 1.398777961730957, Generator loss: 0.5245149731636047\nIteration 302: Discriminator loss: 1.3980170488357544, Generator loss: 0.5246837139129639\nIteration 303: Discriminator loss: 1.397104263305664, Generator loss: 0.5250940918922424\nIteration 304: Discriminator loss: 1.4003713130950928, Generator loss: 0.5257436037063599\nIteration 305: Discriminator loss: 1.3994603157043457, Generator loss: 0.5257079601287842\nIteration 306: Discriminator loss: 1.3984472751617432, Generator loss: 0.5260594487190247\nIteration 307: Discriminator loss: 1.3983149528503418, Generator loss: 0.5269235968589783\nIteration 308: Discriminator loss: 1.398357629776001, Generator loss: 0.5270739793777466\nIteration 309: Discriminator loss: 1.3986541032791138, Generator loss: 0.5271415710449219\nIteration 310: Discriminator loss: 1.3981106281280518, Generator loss: 0.5279309749603271\nIteration 311: Discriminator loss: 1.396660327911377, Generator loss: 0.527762234210968\nIteration 312: Discriminator loss: 1.3966329097747803, Generator loss: 0.5284567475318909\nIteration 313: Discriminator loss: 1.3943767547607422, Generator loss: 0.5284973978996277\nIteration 314: Discriminator loss: 1.3948322534561157, Generator loss: 0.5293087959289551\nIteration 315: Discriminator loss: 1.395643949508667, Generator loss: 0.5293419361114502\nIteration 316: Discriminator loss: 1.3947699069976807, Generator loss: 0.5296772718429565\nIteration 317: Discriminator loss: 1.3954365253448486, Generator loss: 0.529784083366394\nIteration 318: Discriminator loss: 1.3956336975097656, Generator loss: 0.530178427696228\nIteration 319: Discriminator loss: 1.392374038696289, Generator loss: 0.530502438545227\nIteration 320: Discriminator loss: 1.396607756614685, Generator loss: 0.5309666395187378\nIteration 321: Discriminator loss: 1.3935315608978271, Generator loss: 0.5312080979347229\nIteration 322: Discriminator loss: 1.3950668573379517, Generator loss: 0.5314311981201172\nIteration 323: Discriminator loss: 1.3933815956115723, Generator loss: 0.5319499969482422\nIteration 324: Discriminator loss: 1.3925683498382568, Generator loss: 0.5318768620491028\nIteration 325: Discriminator loss: 1.3939180374145508, Generator loss: 0.5323507785797119\nIteration 326: Discriminator loss: 1.3946560621261597, Generator loss: 0.5327405333518982\nIteration 327: Discriminator loss: 1.395316481590271, Generator loss: 0.5326313972473145\nIteration 328: Discriminator loss: 1.391527771949768, Generator loss: 0.5331786870956421\nIteration 329: Discriminator loss: 1.3924596309661865, Generator loss: 0.5332421064376831\nIteration 330: Discriminator loss: 1.3930209875106812, Generator loss: 0.5336830019950867\nIteration 331: Discriminator loss: 1.393012285232544, Generator loss: 0.533909797668457\nIteration 332: Discriminator loss: 1.392447829246521, Generator loss: 0.534070611000061\nIteration 333: Discriminator loss: 1.39076828956604, Generator loss: 0.5345215797424316\nIteration 334: Discriminator loss: 1.3903945684432983, Generator loss: 0.5343550443649292\nIteration 335: Discriminator loss: 1.392783761024475, Generator loss: 0.5347591042518616\nIteration 336: Discriminator loss: 1.390876293182373, Generator loss: 0.5350016355514526\nIteration 337: Discriminator loss: 1.3919408321380615, Generator loss: 0.5351463556289673\nIteration 338: Discriminator loss: 1.3931142091751099, Generator loss: 0.5354093313217163\nIteration 339: Discriminator loss: 1.390161395072937, Generator loss: 0.5354557633399963\nIteration 340: Discriminator loss: 1.3929119110107422, Generator loss: 0.5361737012863159\nIteration 341: Discriminator loss: 1.3898448944091797, Generator loss: 0.5364711284637451\nIteration 342: Discriminator loss: 1.3908369541168213, Generator loss: 0.5365871787071228\nIteration 343: Discriminator loss: 1.389743685722351, Generator loss: 0.5367971658706665\nIteration 344: Discriminator loss: 1.3897333145141602, Generator loss: 0.5367715954780579\nIteration 345: Discriminator loss: 1.3914793729782104, Generator loss: 0.5373475551605225\nIteration 346: Discriminator loss: 1.3894860744476318, Generator loss: 0.5374835729598999\nIteration 347: Discriminator loss: 1.3903775215148926, Generator loss: 0.5376145243644714\nIteration 348: Discriminator loss: 1.3883845806121826, Generator loss: 0.5375823378562927\nIteration 349: Discriminator loss: 1.390099048614502, Generator loss: 0.5383815169334412\nIteration 350: Discriminator loss: 1.390495777130127, Generator loss: 0.5383545756340027\nIteration 351: Discriminator loss: 1.388287901878357, Generator loss: 0.5383847951889038\nIteration 352: Discriminator loss: 1.3870902061462402, Generator loss: 0.5388874411582947\nIteration 353: Discriminator loss: 1.3910952806472778, Generator loss: 0.5390599966049194\nIteration 354: Discriminator loss: 1.388490915298462, Generator loss: 0.5389952659606934\nIteration 355: Discriminator loss: 1.386502742767334, Generator loss: 0.5396003723144531\nIteration 356: Discriminator loss: 1.3890987634658813, Generator loss: 0.5396050214767456\nIteration 357: Discriminator loss: 1.3889251947402954, Generator loss: 0.539299488067627\nIteration 358: Discriminator loss: 1.3870651721954346, Generator loss: 0.5398640632629395\nIteration 359: Discriminator loss: 1.3858041763305664, Generator loss: 0.5401377081871033\nIteration 360: Discriminator loss: 1.3873525857925415, Generator loss: 0.5402747392654419\nIteration 361: Discriminator loss: 1.3864710330963135, Generator loss: 0.5405007600784302\nIteration 362: Discriminator loss: 1.3855206966400146, Generator loss: 0.5410399436950684\nIteration 363: Discriminator loss: 1.3852245807647705, Generator loss: 0.541067361831665\nIteration 364: Discriminator loss: 1.385448932647705, Generator loss: 0.5413155555725098\nIteration 365: Discriminator loss: 1.3843858242034912, Generator loss: 0.5416511297225952\nIteration 366: Discriminator loss: 1.3854844570159912, Generator loss: 0.5414364337921143\nIteration 367: Discriminator loss: 1.384690284729004, Generator loss: 0.5419820547103882\nIteration 368: Discriminator loss: 1.3840510845184326, Generator loss: 0.5421620011329651\nIteration 369: Discriminator loss: 1.383650779724121, Generator loss: 0.542130172252655\nIteration 370: Discriminator loss: 1.3852699995040894, Generator loss: 0.542462170124054\nIteration 371: Discriminator loss: 1.384529709815979, Generator loss: 0.5426015853881836\nIteration 372: Discriminator loss: 1.3860474824905396, Generator loss: 0.5423948764801025\nIteration 373: Discriminator loss: 1.3837640285491943, Generator loss: 0.5432544946670532\nIteration 374: Discriminator loss: 1.3842813968658447, Generator loss: 0.5431568622589111\nIteration 375: Discriminator loss: 1.383354663848877, Generator loss: 0.543475866317749\nIteration 376: Discriminator loss: 1.384674072265625, Generator loss: 0.5433923602104187\nIteration 377: Discriminator loss: 1.3852115869522095, Generator loss: 0.543592095375061\nIteration 378: Discriminator loss: 1.382265567779541, Generator loss: 0.5439792275428772\nIteration 379: Discriminator loss: 1.3826837539672852, Generator loss: 0.5439438819885254\nIteration 380: Discriminator loss: 1.3862438201904297, Generator loss: 0.5439406633377075\nIteration 381: Discriminator loss: 1.384634256362915, Generator loss: 0.5442410111427307\nIteration 382: Discriminator loss: 1.379882574081421, Generator loss: 0.5447448492050171\nIteration 383: Discriminator loss: 1.380720853805542, Generator loss: 0.5448981523513794\nIteration 384: Discriminator loss: 1.381971836090088, Generator loss: 0.5445743799209595\nIteration 385: Discriminator loss: 1.381757378578186, Generator loss: 0.544903039932251\nIteration 386: Discriminator loss: 1.38173508644104, Generator loss: 0.545240044593811\nIteration 387: Discriminator loss: 1.384911298751831, Generator loss: 0.5451136827468872\nIteration 388: Discriminator loss: 1.3814353942871094, Generator loss: 0.5453548431396484\nIteration 389: Discriminator loss: 1.3818106651306152, Generator loss: 0.544735312461853\nIteration 390: Discriminator loss: 1.3822613954544067, Generator loss: 0.5451037883758545\nIteration 391: Discriminator loss: 1.3850247859954834, Generator loss: 0.545487642288208\nIteration 392: Discriminator loss: 1.3822611570358276, Generator loss: 0.5453518629074097\nIteration 393: Discriminator loss: 1.3824788331985474, Generator loss: 0.5455001592636108\nIteration 394: Discriminator loss: 1.3838768005371094, Generator loss: 0.5454081296920776\nIteration 395: Discriminator loss: 1.382599949836731, Generator loss: 0.5456814765930176\nIteration 396: Discriminator loss: 1.3842854499816895, Generator loss: 0.5458225607872009\nIteration 397: Discriminator loss: 1.382411241531372, Generator loss: 0.5460293292999268\nIteration 398: Discriminator loss: 1.385209560394287, Generator loss: 0.5459659695625305\nIteration 399: Discriminator loss: 1.380989670753479, Generator loss: 0.5460994839668274\nIteration 400: Discriminator loss: 1.3814029693603516, Generator loss: 0.5461331605911255\nIteration 401: Discriminator loss: 1.3816876411437988, Generator loss: 0.5463026762008667\nIteration 402: Discriminator loss: 1.383217453956604, Generator loss: 0.5465100407600403\nIteration 403: Discriminator loss: 1.3857831954956055, Generator loss: 0.5463284254074097\nIteration 404: Discriminator loss: 1.3836578130722046, Generator loss: 0.5469070672988892\nIteration 405: Discriminator loss: 1.381866216659546, Generator loss: 0.5468469858169556\nIteration 406: Discriminator loss: 1.3819576501846313, Generator loss: 0.5469557046890259\nIteration 407: Discriminator loss: 1.3819172382354736, Generator loss: 0.546924889087677\nIteration 408: Discriminator loss: 1.3822901248931885, Generator loss: 0.5471464395523071\nIteration 409: Discriminator loss: 1.3832581043243408, Generator loss: 0.5470714569091797\nIteration 410: Discriminator loss: 1.3833211660385132, Generator loss: 0.5471622943878174\nIteration 411: Discriminator loss: 1.3834378719329834, Generator loss: 0.5473785400390625\nIteration 412: Discriminator loss: 1.3842506408691406, Generator loss: 0.5477688908576965\nIteration 413: Discriminator loss: 1.384239673614502, Generator loss: 0.5479294061660767\nIteration 414: Discriminator loss: 1.3823130130767822, Generator loss: 0.5478469133377075\nIteration 415: Discriminator loss: 1.3844020366668701, Generator loss: 0.5475177764892578\nIteration 416: Discriminator loss: 1.3826632499694824, Generator loss: 0.5479539036750793\nIteration 417: Discriminator loss: 1.3858104944229126, Generator loss: 0.5479058027267456\nIteration 418: Discriminator loss: 1.381096601486206, Generator loss: 0.5483566522598267\nIteration 419: Discriminator loss: 1.3842127323150635, Generator loss: 0.5486186146736145\nIteration 420: Discriminator loss: 1.384232759475708, Generator loss: 0.5485860705375671\nIteration 421: Discriminator loss: 1.3827499151229858, Generator loss: 0.5489436984062195\nIteration 422: Discriminator loss: 1.3820128440856934, Generator loss: 0.549066960811615\nIteration 423: Discriminator loss: 1.3824166059494019, Generator loss: 0.5492068529129028\nIteration 424: Discriminator loss: 1.384058952331543, Generator loss: 0.5492454767227173\nIteration 425: Discriminator loss: 1.3814992904663086, Generator loss: 0.5497270822525024\nIteration 426: Discriminator loss: 1.3845109939575195, Generator loss: 0.5496549010276794\nIteration 427: Discriminator loss: 1.3840117454528809, Generator loss: 0.5497399568557739\nIteration 428: Discriminator loss: 1.3845188617706299, Generator loss: 0.5501172542572021\nIteration 429: Discriminator loss: 1.3810949325561523, Generator loss: 0.5499783158302307\nIteration 430: Discriminator loss: 1.3830578327178955, Generator loss: 0.5503997206687927\nIteration 431: Discriminator loss: 1.3835067749023438, Generator loss: 0.5505574345588684\nIteration 432: Discriminator loss: 1.3829119205474854, Generator loss: 0.550837516784668\nIteration 433: Discriminator loss: 1.3840348720550537, Generator loss: 0.5510038137435913\nIteration 434: Discriminator loss: 1.3801335096359253, Generator loss: 0.5513694286346436\nIteration 435: Discriminator loss: 1.3833485841751099, Generator loss: 0.5513736009597778\nIteration 436: Discriminator loss: 1.3830205202102661, Generator loss: 0.5515137314796448\nIteration 437: Discriminator loss: 1.3861037492752075, Generator loss: 0.5517306327819824\nIteration 438: Discriminator loss: 1.3804304599761963, Generator loss: 0.5524321794509888\nIteration 439: Discriminator loss: 1.383059024810791, Generator loss: 0.5523184537887573\nIteration 440: Discriminator loss: 1.3838913440704346, Generator loss: 0.5525667071342468\nIteration 441: Discriminator loss: 1.3828665018081665, Generator loss: 0.5528125762939453\nIteration 442: Discriminator loss: 1.3816475868225098, Generator loss: 0.5532640218734741\nIteration 443: Discriminator loss: 1.3822288513183594, Generator loss: 0.553213357925415\nIteration 444: Discriminator loss: 1.3845841884613037, Generator loss: 0.5534435510635376\nIteration 445: Discriminator loss: 1.3797504901885986, Generator loss: 0.5543114542961121\nIteration 446: Discriminator loss: 1.3831981420516968, Generator loss: 0.5541879534721375\nIteration 447: Discriminator loss: 1.3870453834533691, Generator loss: 0.554394006729126\nIteration 448: Discriminator loss: 1.3826584815979004, Generator loss: 0.5543922185897827\nIteration 449: Discriminator loss: 1.3836555480957031, Generator loss: 0.5547192096710205\nIteration 450: Discriminator loss: 1.381246566772461, Generator loss: 0.5549947023391724\nIteration 451: Discriminator loss: 1.3845669031143188, Generator loss: 0.5549675822257996\nIteration 452: Discriminator loss: 1.3851096630096436, Generator loss: 0.55502849817276\nIteration 453: Discriminator loss: 1.3824970722198486, Generator loss: 0.555631160736084\nIteration 454: Discriminator loss: 1.3803074359893799, Generator loss: 0.5555185079574585\nIteration 455: Discriminator loss: 1.3854951858520508, Generator loss: 0.5557608604431152\nIteration 456: Discriminator loss: 1.379610300064087, Generator loss: 0.5561256408691406\nIteration 457: Discriminator loss: 1.3827311992645264, Generator loss: 0.555884599685669\nIteration 458: Discriminator loss: 1.3820760250091553, Generator loss: 0.5563929080963135\nIteration 459: Discriminator loss: 1.3808045387268066, Generator loss: 0.5568537712097168\nIteration 460: Discriminator loss: 1.384317398071289, Generator loss: 0.5565504431724548\nIteration 461: Discriminator loss: 1.3859691619873047, Generator loss: 0.5567162036895752\nIteration 462: Discriminator loss: 1.3807555437088013, Generator loss: 0.557132363319397\nIteration 463: Discriminator loss: 1.3826038837432861, Generator loss: 0.556925892829895\nIteration 464: Discriminator loss: 1.383055567741394, Generator loss: 0.5571357011795044\nIteration 465: Discriminator loss: 1.384275197982788, Generator loss: 0.5573543310165405\nIteration 466: Discriminator loss: 1.3841662406921387, Generator loss: 0.557187557220459\nIteration 467: Discriminator loss: 1.3830440044403076, Generator loss: 0.5574275851249695\nIteration 468: Discriminator loss: 1.383605718612671, Generator loss: 0.5575457215309143\nIteration 469: Discriminator loss: 1.3842430114746094, Generator loss: 0.5575369596481323\nIteration 470: Discriminator loss: 1.383286952972412, Generator loss: 0.5576339364051819\nIteration 471: Discriminator loss: 1.3846254348754883, Generator loss: 0.5576439499855042\nIteration 472: Discriminator loss: 1.383747935295105, Generator loss: 0.5575109124183655\nIteration 473: Discriminator loss: 1.386715054512024, Generator loss: 0.5574755668640137\nIteration 474: Discriminator loss: 1.3835158348083496, Generator loss: 0.5575962066650391\nIteration 475: Discriminator loss: 1.3829491138458252, Generator loss: 0.5577213764190674\nIteration 476: Discriminator loss: 1.3828712701797485, Generator loss: 0.5577650666236877\nIteration 477: Discriminator loss: 1.383022427558899, Generator loss: 0.5578504800796509\nIteration 478: Discriminator loss: 1.3842228651046753, Generator loss: 0.5577492117881775\nIteration 479: Discriminator loss: 1.3857142925262451, Generator loss: 0.557502269744873\nIteration 480: Discriminator loss: 1.3828506469726562, Generator loss: 0.5580268502235413\nIteration 481: Discriminator loss: 1.3849563598632812, Generator loss: 0.5579253435134888\nIteration 482: Discriminator loss: 1.3833510875701904, Generator loss: 0.5573546290397644\nIteration 483: Discriminator loss: 1.3873733282089233, Generator loss: 0.5577358603477478\nIteration 484: Discriminator loss: 1.3842095136642456, Generator loss: 0.5570918321609497\nIteration 485: Discriminator loss: 1.3840305805206299, Generator loss: 0.5578195452690125\nIteration 486: Discriminator loss: 1.3881573677062988, Generator loss: 0.5574420690536499\nIteration 487: Discriminator loss: 1.3824255466461182, Generator loss: 0.5574735403060913\nIteration 488: Discriminator loss: 1.3841986656188965, Generator loss: 0.5569090247154236\nIteration 489: Discriminator loss: 1.387085199356079, Generator loss: 0.5571598410606384\nIteration 490: Discriminator loss: 1.383397102355957, Generator loss: 0.556973934173584\nIteration 491: Discriminator loss: 1.3851016759872437, Generator loss: 0.5568363666534424\nIteration 492: Discriminator loss: 1.3839972019195557, Generator loss: 0.5573002099990845\nIteration 493: Discriminator loss: 1.3904459476470947, Generator loss: 0.5565720796585083\nIteration 494: Discriminator loss: 1.3885834217071533, Generator loss: 0.5564247369766235\nIteration 495: Discriminator loss: 1.3875775337219238, Generator loss: 0.5561203956604004\nIteration 496: Discriminator loss: 1.3871134519577026, Generator loss: 0.5563935041427612\nIteration 497: Discriminator loss: 1.3896311521530151, Generator loss: 0.555980920791626\nIteration 498: Discriminator loss: 1.3823578357696533, Generator loss: 0.55599045753479\nIteration 499: Discriminator loss: 1.386501669883728, Generator loss: 0.5559850931167603\n"
    }
   ],
   "source": [
    "gan.train_explicit(epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 251.565 248.518125 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\nL 244.365 7.2 \r\nL 26.925 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p5592966c71)\">\r\n    <image height=\"218\" id=\"imageee051bfcb3\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.64\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mf55efbaf74\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#mf55efbaf74\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#mf55efbaf74\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#mf55efbaf74\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#mf55efbaf74\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#mf55efbaf74\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#mf55efbaf74\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m4a5aaddfd6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4a5aaddfd6\" y=\"11.082857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4a5aaddfd6\" y=\"49.911429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4a5aaddfd6\" y=\"88.74\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4a5aaddfd6\" y=\"127.568571\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4a5aaddfd6\" y=\"166.397143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4a5aaddfd6\" y=\"205.225714\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 224.64 \r\nL 26.925 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 224.64 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.2 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p5592966c71\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = gan.generate()\n",
    "plt.imshow(img[0, :,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.export(\"gan/models/dcgan test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gan.import_('gan/models/dcgan test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "noise = np.random.normal(0, 1, (5, 100))\n",
    "batch_fake = gan.generator.predict(noise)\n",
    "\n",
    "res = gan.discriminator.predict(batch_fake)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = gan.discriminator.predict(x_train[15:20])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599835655011",
   "display_name": "Python 3.7.6 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}