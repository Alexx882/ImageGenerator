{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Images of Faces with Generative Adversarial Networks\n",
    "by Manuel Herold and Alexander Lercher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "Our goal was the generation of images of humans with artificial neural networks (ANNs). We discovered that images of human bodies are extremely hard to generate as many research papers currently only focus on faces and training data for whole body postures is rare and oftentimes not aligned.\n",
    "We already identified this problem in the proposal and chose images of faces as fallback plan.\n",
    "\n",
    "For our project we used a Generative Adversarial Network (GAN) to create images of faces. There, two ANNs are connected in a way that they try to outsmart each other during training. The _generator_ generates new images of faces while the _discriminator_ tries to distinguish them from real ones [1].\n",
    "\n",
    "Both networks and the training process were implemented from scratch in Python by using TensorFlow's machine learning framework [2].\n",
    "\n",
    "The tasks for the project were split as follows:\n",
    "\n",
    "| Task                       | Team member       | Description                     |\n",
    "|----------------------------|-------------------|---------------------------------|\n",
    "| Training Data Collection   | Manuel; Alexander | Collection of raw images        |\n",
    "| Training Data Alignment    | Manuel            | Training data preparation       |\n",
    "| GAN Training Pipeline      | Alexander         | Training process implementation |\n",
    "| GAN Reference Architecture | Alexander         | Image generation with [3, 4]       |\n",
    "| GAN VAE Noise Input        | Manuel            | Image generation with [5]       |\n",
    "\n",
    "The remainder of this report contains my contributions including their theory. If Manuel's contributions are needed to understand mine they will be explicitly marked as his.\n",
    "\n",
    "[1] https://developers.google.com/machine-learning/gan\n",
    "\n",
    "[2] https://www.tensorflow.org/\n",
    "\n",
    "[3] https://arxiv.org/pdf/1511.06434.pdf \n",
    "\n",
    "[4] https://arxiv.org/pdf/1711.06491.pdf\n",
    "\n",
    "[5] @misc{zhong2018generative,\n",
    "    title={Generative Adversarial Networks with Decoder-Encoder Output Noise},\n",
    "    author={Guoqiang Zhong and Wei Gao and Yongbin Liu and Youzhao Yang},\n",
    "    year={2018},\n",
    "    eprint={1807.03923},\n",
    "    archivePrefix={arXiv},\n",
    "    primaryClass={cs.CV}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "We needed real images of faces for the training process so the GAN can learn how newly generated images should look like. \n",
    "\n",
    "First, we implemented a web crawling script to download images from public websites featuring models. Unfortunately, this approach had the problem that most images were discarded during alignment.\n",
    "\n",
    "Next, we downloaded multiple professional datasets from research papers or Kaggle competitions. In the end, the training process was done with the [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset, which contains 200,000 images of celebrity faces.\n",
    "\n",
    "### Preparation\n",
    "The dataset was prepared in a way that \n",
    "images are converted to greyscale (1 channel),\n",
    "the image dimensions match our desired size (256x256), \n",
    "and faces are in the middle of the cropped image. \n",
    "Methods for face detection and cropping were implemented by Manuel.\n",
    "Furthermore, the images were combined to batches of size 64 and stored on disk as large numpy arrays with resulting shapes (64, 256, 256, 1).\n",
    "\n",
    "The following method from ```training_images/training_data_provider.py``` is used to retrieve the prepared image batches as numpy arrays during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_training_images_in_batches_from_disk(self) -> Iterable[np.ndarray]:\n",
    "        '''\n",
    "        Loads preprocessed image arrays from files. Memory load is not that high, as only individual batches are read in.\n",
    "        The batch size is fixed to 64.\n",
    "\n",
    "        :returns: same as self.get_all_training_images_in_batches() but slightly faster.\n",
    "        '''\n",
    "        if not os.path.exists(self.npy_data_path):\n",
    "            raise IOError(f\"The training arrays folder {self.npy_data_path} does not exist.\")\n",
    "\n",
    "        for _, _, files in os.walk(self.npy_data_path):\n",
    "            random.shuffle(files)\n",
    "            for file_ in files:\n",
    "                yield np.load(os.path.join(self.npy_data_path, file_), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations\n",
    "If we could not detect a face, the image was discarded from the training set. For all other images the face was moved to the center.\n",
    "\n",
    "This aids the training process where the discriminator must learn how a valid face looks like. As all faces are in the center the discriminator successfully learns to focus on this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Basics\n",
    "As already explained, the GAN consists of two ANNs.\n",
    "The _generator_ generates new images of faces while the _discriminator_ tries to distinguish them from real ones [1].\n",
    "The basic architecture is visualized in figure 1.\n",
    "\n",
    "![Basic Architecture](https://developers.google.com/machine-learning/gan/images/gan_diagram.svg)\n",
    "_Figure 1: Basic GAN Architecture_\n",
    "\n",
    "### Discriminator Goal\n",
    "The discriminator's goal is to correctly classify input images from two classes: fake and real. Real images are taken from the CelebA[x] dataset. Fake images are generated by the Generator.\n",
    "The loss function for the discriminator is the following [6]:\n",
    "\n",
    "\\begin{equation*}\n",
    "L(D) = -\\frac{1}{2} log (D(x)) -\\frac{1}{2} log (1 - D(G(z)))\n",
    "\\end{equation*}\n",
    "\n",
    "Intuitively, the first part represents real data x which should be classified as real with D(x)=1. The second part represents fake data from the generator which should be classified as fake with D(G(z))=0.\n",
    "\n",
    "### Generator Goal\n",
    "The generator's goal is the generation of realistic images based on the real images. Therefore its goal is opposite from the discriminator's:\n",
    "\n",
    "\\begin{equation*}\n",
    "L(G) = - log (D(G(z)))\n",
    "\\end{equation*}\n",
    "\n",
    "Here, the generator's output should be classified as real with D(G(z))=1, where _z_ is random input for the generator.\n",
    "\n",
    "[6] https://arxiv.org/pdf/1711.06491.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Additional Sources for Report\n",
    "\n",
    "- [explanation of transposed convolution _Conv2DTranspose_ to apply for generator (increase image size)](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d)\n",
    "\n",
    "https://datagrid.co.jp/en/all/release/386/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
